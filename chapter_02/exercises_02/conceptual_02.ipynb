{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. For each of parts (a) through (d), indicate whether we would generally\n",
    "expect the performance of a flexible statistical learning method to be\n",
    "better or worse than an inflexible method. Justify your answer.\n",
    "(a) The sample size n is extremely large, and the number of predic-\n",
    "tors p is small.\n",
    "\n",
    "flexible expected to outperform due to large sample size, which can be inferred to reduce variance, which would lead to higher MSE with a more flexible model. \n",
    "\n",
    "(b) The number of predictors p is extremely large, and the number\n",
    "of observations n is small.\n",
    "\n",
    "inflexible is less likely to overfit a small sample size than a flexible model, so inflexible will outperform\n",
    "\n",
    "(c) The relationship between the predictors and response is highly\n",
    "non-linear.\n",
    "\n",
    "flexible will outperform due to non linear relationship\n",
    "\n",
    "(d) The variance of the error terms, i.e. σ2 = Var(\"), is extremely\n",
    "high\n",
    "\n",
    "inflexible will outperform as flexible models exacerbate variance, which would cause MSE to go even higher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Explain whether each scenario is a classification or regression prob-\n",
    "lem, and indicate whether we are most interested in inference or pre-\n",
    "diction. Finally, provide n and p.\n",
    "(a) We collect a set of data on the top 500 firms in the US. For each\n",
    "firm we record profit, number of employees, industry and the\n",
    "CEO salary. We are interested in understanding which factors\n",
    "affect CEO salary.\n",
    "\n",
    "regression, as CEO salary exists on a continuous numeric range (unless arbitrarily put in buckets), inference, as we are interested in what factors affect CEO salary, meaning we want to understand the relationships rather than make predictions.\n",
    "\n",
    "(b) We are considering launching a new product and wish to know\n",
    "whether it will be a success or a failure. We collect data on 20\n",
    "similar products that were previously launched. For each prod-\n",
    "uct we have recorded whether it was a success or failure, price\n",
    "charged for the product, marketing budget, competition price,\n",
    "and ten other variables.\n",
    "\n",
    "classification, as the new product will be classified either as a success or failure, prediction, as the outcome is most important, not the relationships in the data.\n",
    "\n",
    "\n",
    "(c) We are interested in predicting the % change in the USD/Euro\n",
    "exchange rate in relation to the weekly changes in the world\n",
    "stock markets. Hence we collect weekly data for all of 2012. For\n",
    "each week we record the % change in the USD/Euro, the %\n",
    "change in the US market, the % change in the British market,\n",
    "and the % change in the German market.\n",
    "\n",
    "regression, as the % change in exchange rate, a continuous numeric value, is the point of interest, prediction, because we wish to predict it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. We now revisit the bias-variance decomposition.\n",
    "(a) Provide a sketch of typical (squared) bias, variance, training er-\n",
    "ror, test error, and Bayes (or irreducible) error curves, on a sin-\n",
    "gle plot, as we go from less flexible statistical learning methods\n",
    "towards more flexible approaches. The x-axis should represent\n",
    "the amount of flexibility in the method, and the y-axis should\n",
    "represent the values for each curve. There should be five curves.\n",
    "Make sure to label each one.\n",
    "\n",
    "flexibility starts low, increases (x-axis)\n",
    "bias starts high, tapers off towards the middle of the plot\n",
    "variance starts low, increases as flexibility increases\n",
    "as the training error steadily decreases towards a 0% error rate, the test error decreases, then increases again as the model begins to overfit the data\n",
    "the bayes error is constant by definition\n",
    "\n",
    "(b) Explain why each of the five curves has the shape displayed in\n",
    "part (a).\n",
    "\n",
    "higher flexibility results in higher variance as more flexible models will fit the data more closely, so any change in the data will have a larger effect\n",
    "\n",
    "lower flexibilty results in higher bias as inflexible models oversimplify real-life problems (bias), which may not always be linear or otherwise simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. You will now think of some real-life applications for statistical learn-\n",
    "ing.\n",
    "(a) Describe three real-life applications in which classification might\n",
    "be useful. Describe the response, as well as the predictors. Is the\n",
    "goal of each application inference or prediction? Explain your\n",
    "answer.\n",
    "\n",
    "predicting or making inferences on static outcomes, like survival vs. death, or otherwise putting things into buckets\n",
    "    - predicting risk of heart disease to encourage proper intervention, based on predictors like age, weight, smoking frequency, cholesterol levels, blood sugar levels\n",
    "    - for less well-documented diseases, inferring (inferencing?) health outcomes based on predictors like age, weight, genetics, proximity to contagious victim, duration of exposure, etc.\n",
    "    - election outcomes: 538 might be interested in predicting outcomes, politicians more interested in inferring optimal positions based on past election's predictors like stance on abortion, death penalty, cannabis legalization, etc.\n",
    "\n",
    "(b) Describe three real-life applications in which regression might\n",
    "be useful. Describe the response, as well as the predictors. Is the\n",
    "goal of each application inference or prediction? Explain your\n",
    "answer.\n",
    "\n",
    "    - predicting/inferring house prices based on predictors like sq footage, age, stories, etc. people may want to predict prices for a given home, identify undervalued homes, or predict average prices given a change in the housing stock data, or homeowners may want to maximize the value of an existing home (inference)\n",
    "    - predicting the stock market, based on predictors like value of competitor's stock, recent news about a company, direction of market overall, will a given stock rise and by how much? classification not really relevant to this as increase vs. decrease is irrelevant given range of numbers\n",
    "    - predicting horse races - either prediction or inference, famous anecdote of comprehensive analysis of living and dead champion racehorses finds main predictor of success to be size of heart/ventricle/something (inference), so bet on a horse based on its heart size (prediction)\n",
    "\n",
    "(c) Describe three real-life applications in which cluster analysis\n",
    "might be useful\n",
    "\n",
    "    - famous anecdote of baseball (538 nate silver?), not sure if cluster analysis but clustering baseball players based on career stats, comparing past players at arbitrary points, say 5 or 10 years in league, where were they, cluster together with modern players with 5, 10 years in league, identify future MLB success based on similarities between top players of past at 5 years and current players at 5 years\n",
    "    - clustering dna based on relatedness to identify or predict lineage, do genetic analysis of various organisms to identify closely related species\n",
    "    - based on past natural disasters, use predictors to cluster current natural disaster with previous ones in order to predict damage, identify need for evacuation, send resources, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. What are the advantages and disadvantages of a very flexible (versus\n",
    "a less flexible) approach for regression or classification? Under what\n",
    "circumstances might a more flexible approach be preferred to a less\n",
    "flexible approach? When might a less flexible approach be preferred?\n",
    "\n",
    "Very flexible - advantages: less bias, can fit the data better especially given large datasets. disadvantages: can overfit, have higher variance especially with smaller sample sizes. Flexible preferred with larger datasets, more complex, non linear relationships. Less flexible preferred with smaller datasets, more linear, simple relationships."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Describe the differences between a parametric and a non-parametric\n",
    "statistical learning approach. What are the advantages of a para-\n",
    "metric approach to regression or classification (as opposed to a non-\n",
    "parametric approach)? What are its disadvantages?\n",
    "\n",
    "parametric - 2 step model based approach, first make assumption about shape of f (ie. f(x) is linear). second, need a procedure that uses training data to fit or train the model, in case of linear, need coefficients for the variables. Parametric refers to the fact that this approach revolves around the estimation of parameters via training. advantages include less risk of overfitting, smaller required sample size, disadvantages include the assumption of a particular function shape which can oversimplify the reality of the data and not fit it correctly\n",
    "\n",
    "non-parametric - don't just assume functional form of f, estimate f as closely to data points as possible without rough/wiggly parts. advantages include higher ability to fit complex function shapes, disadvantages include that a very large number of observations is required with non-parametric methods to avoid overfitting.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. The table below provides a training data set containing six observa-\n",
    "tions, three predictors, and one qualitative response variable.\n",
    "Obs. X1 X2 X3 Y\n",
    "1 0 3 0 Red\n",
    "2 2 0 0 Red\n",
    "3 0 1 3 Red\n",
    "4 0 1 2 Green\n",
    "5 −1 0 1 Green\n",
    "6 1 1 1 Red\n",
    "Suppose we wish to use this data set to make a prediction for Y when\n",
    "X1 = X2 = X3 = 0 using K-nearest neighbors.\n",
    "(a) Compute the Euclidean distance between each observation and\n",
    "the test point, X1 = X2 = X3 = 0.\n",
    "\n",
    "obs e_dist\n",
    "1   3\n",
    "2   2\n",
    "3   root 10 (~3.25)\n",
    "4   root 5 (~2.4)\n",
    "5   root 2 (~ 1.4)\n",
    "6   root 3 (~1.8)\n",
    "\n",
    "(b) What is our prediction with K = 1? Why?\n",
    "\n",
    "Green, as the KNN for K = 1 is (points) [5=Green]\n",
    "\n",
    "(c) What is our prediction with K = 3? Why?\n",
    "\n",
    "Red, as the KNN for K = 3 is (points) [5=Green, 6=Red, 2=Red]\n",
    "\n",
    "(d) If the Bayes decision boundary in this problem is highly non-\n",
    "linear, then would we expect the best value for K to be large or\n",
    "small? Why?\n",
    "\n",
    "small but not too small (U-shaped error). We do not want the function to overfit with a small K value, but K value that is too large would start to approximate a linear relationship (overly inflexible)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ISLP_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
